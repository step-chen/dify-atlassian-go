MIF2HDB

Prep story for a MIF2HDB Converter/Compiler to be used while limited HDB
data is available. \\

**Goals**:

-   The MIF specification (V3.07_20170525) is valid for urban data,
    which is not supported by the current HDB specification
    (V2.04.06_20171024). The MIF2HDB Compiler should somehow retain the
    available urban data.
-   The current MIF2DH Converter is a single-threaded Python script.
    MIF2HDB+HDB2DH should aim to be faster.
-   While the HDB2DH Compiler is under construction, having a secondary
    way to create DHive data for comparison is a bonus. This means
    ideally MIF2HDB would have a direct way to create DHive and HDB
    databases.

**For consideration**:

-   HDB data currently duplicates data (nodes) on mesh borders, and
    gives them a unique permanent Id. During HDB 2 DH conversion, the
    duplicated nodes are merged to one permanent Id, and all tables
    which refer to these nodes are updated. MIF data has mesh
    information, but doesn't duplicate data (nodes) on mesh borders. Not
    creating an HDB HAD_MESH_CONNECT table during MIF 2 HDB and keeping
    the border node permanent Ids in sync would reduce the runtime, but
    will not test the de-duplication code in the HDB 2 DH converter.

-   Will the HAD MIF samples even contain urban data?

-   How can a speed gain be realized? Will using a Python compiler help
    for speed? Will a direct conversion to C++ from Python Help? Most
    work is done in SQL, so compilation might not help much.

-   Can the MIF data be processed in parallel like is done for HDB data
    now?

-   Are all required indices in place in the HAD2DH.py script?

-   The current MIF spec specifies Mesh for some tables, not all.

-   The amount of MIF test data with Mesh fields is very limited.

**Possible approaches**:

-   Convert the current python scripting to a MIF2DH compiler, using the
    MIF mesh information for parallelism. The output should be HDB or DH
    depending on a parameter.

-   Add threading to the python code and/or compile the python code?

**Experiment results**:

-   Using a Python compiler (Nuitka.net) for HAD2DH.py without any code
    changes resulted in a conversion time for MIF2DH of 33 cpu seconds
    compared to (also) 33 cpu seconds for the interpreted script.
-   Profile HAD2DH.py:

2286578 function calls (2286504 primitive calls) in 34.028 seconds

Ordered by: internal time

ncalls tottime percall cumtime percall filename:lineno(function)

2 21.609 10.804 21.609 10.804 {[]{#anchor}posix.system} ‚Üê call to
HAD2DH.sql

14636 9.641 0.001 9.681 0.001 {method \'execute\' of \'sqlite3.Cursor\'
objects}

24 1.772 0.074 1.919 0.080 {method \'executemany\' of \'sqlite3.Cursor\'
objects}

1 0.429 0.429 34.028 34.028 HAD2DH:10(\<module\>)

128603 0.133 0.000 0.147 0.000 HAD2DH:219(iterMidFile)

48523 0.040 0.000 0.040 0.000 HAD2DH:116(isfloat)

678406 0.037 0.000 0.037 0.000 {method \'upper\' of \'str\' objects}

> Most of the time is spend in sql, which means turning HAD2DH into a
> compiled program won't bring much improvement. Investigation of the
> sql showed a few sub-optimal queries. These queries have been
> addressed, halving the execution time of HAD2DH.sql

-   HAD2DH with HDB input is now (much) faster as HDB2DH for the 9mesh
    sample. We need bigger data to test with. **Update:** With a 144
    mesh generated from the 9mesh data sample, the parallel approach of
    HDB2DH starts to pay off. CPU times for the old and new flow are
    comparable, but walltime for the new flow is about a third of the
    old flow. This is with the current state of the HDB2DH compiler,
    which does not take objects into account.
-   Attached to the jira task HAD-425 is a script to duplicate mesh data
    to generate bigger HDB test data. The HDB2DH conversion process
    crashed on this because it tried to attach all split Dbs. See ticket
    HAD-437.

**Proposal**:

Create the MIF2HDB converter in two steps. This will quickly lead to
results, and allow for testing as development proceeds.

MIF DHImportHAD DHive

'DHDiff' (confidence testing)

HDB HDB2DH DHive\*

First, while the HDB spec is not complete, make DHImportHAD export an
HDB db early on in the MIF import and spawn a HDB2DH process. Then
convert the imported MIF data and the HDB to DHive in parallel. This
enables testing of the HDB2DH output against 'original' output while the
implementation is becoming more mature.

MIF DHImportHAD DHive

'DHDiff' (confidence testing)

'MIF-DB 2 HDB\` HDB2DH DHive\*

Second, when more test data becomes available and/or the HDB spec
includes urban data, use a parallel approach to convert a db with raw
MIF data to HDB (MIF-DB2HDB).

WBS:

-   Create HDB tables.

-   Import MIF:

    -   Create db tables using the existing python scripting.
    -   Add mesh (Id) field for all tables. In the current MIF spec,
        some tables have a Mesh field, not all.
    -   Most of our test MIF db's are not meshed yet; Create a mesh for
        these?
    -   Duplicate mesh-border elements (nodes and chains).
    -   Test HDB2DH_SplitMesh.

-   Fill HDB tables required for the initial split based on geostructure
    (DH_CHA, DH_LAN, DH_NOD):

    -   HAD_LINK,
    -   HAD_LANE_LINK, HAD_LINK_FORM and
    -   HAD_NODE.
    -   Test HDB2DH_GeoStructure and HDB2DH_Merge.

-   Fill HDB tables for topology/attributes:

    -   HAD_POSITION,
    -   HAD_LANE_TOPO_DETAIL,
    -   HAD_LANE_MARK_LINK,
    -   HAD_LANE_MARK_REL,
    -   HAD_NODE_CURVATURE, (HAD_LANE_NODE_CURVATURE,) HAD_LANE_SLOPE,
        (HAD_LANE_NODE_SLOPE,)
    -   HAD_TOLLGATE

-   Fill object related tables. See ticket HAD-430 for the affected
    tables.

  ------------------------------ ----- --
  HDB                            MIF   
  HAD_LINK                             
  HAD_LINK_FORM                        
  HAD_NODE                             
  HAD_NODE_FORM                        
  HAD_POSITION                         
  HAD_NODE_SLOPE                       
  HAD_NODE_CURVATURE                   
  HAD_LANE_LINK                        
  HAD_LANE_TRANSZONE_OFFSET            
  HAD_LANE_NODE                        
  HAD_LANE_POSITION                    
  HAD_LANE_NODE_SLOPE                  
  HAD_LANE_NODE_CURVATURE              
  HAD_LANE_SPEEDLIMIT                  
  HAD_LANE_MARK_LINK                   
  HAD_LANE_MARK_NODE                   
  HAD_LANE_TOPO_DETAIL                 
  HAD_LANE_MARK_REL                    
  HAD_TOLLGATE                         
  HAD_OBJECT_TRAFFIC_BARRIER           
  HAD_OBJECT_OVERHEAD_CROSSING         
  HAD_OBJECT_CURB                      
  HAD_OBJECT_TUNNEL                    
  HAD_OBJECT_TRAFFIC_SIGN              
  HAD_OBJECT_MESSAGE_SIGN              
  HAD_OBJECT_DELINEATOR                
  HAD_OBJECT_TOLL_BOOTH                
  HAD_OBJECT_CALL_BOX                  
  HAD_OBJECT_DITCH                     
  HAD_OBJECT_LINE_POLE                 
  HAD_OBJECT_BOX_POLE                  
  HAD_OBJECT_WALL                      
  HAD_OBJECT_ARROW                     
  HAD_OBJECT_TEXT                      
  HAD_OBJECT_SYMBOL                    
  HAD_OBJECT_WARNING_AREA              
  HAD_OBJECT_FILL_AREA                 
  HAD_OBJECT_TRAFFIC_LIGHTS            
  HAD_OBJECT_GANTRY                    
  HAD_OBJECT_BUILDING                  
  HAD_OBJECT_LINK_REL                  
  HAD_OBJECT_LANE_LINK_REL             
  HAD_MESH_CONNECT                     
  ------------------------------ ----- --
